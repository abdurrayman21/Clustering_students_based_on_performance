# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file located at
    https://colab.research.google.com/drive/1o3Frr_MGbHq7TwzjdmlMVx5GxemvDcFx
"""

# Importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import warnings
import gradio as gr
import plotly.graph_objects as go
import plotly.express as px
import os
import datetime
import json

# Import OpenAI library
from openai import OpenAI
from dotenv import load_dotenv
import joblib

# ‚ö†Ô∏è IMPORTANT: Set your OpenAI API key securely
# It's best practice to load this from an environment variable
# For example: export OPENAI_API_KEY='sk-your-key-here'
# Using the provided key directly for this demo. In production, prefer environment variables.
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY) # Corrected parameter name from 'api_key' to 'api_api_key'

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Global variables to store data and model results across Gradio calls
global_df = None
global_scaled_df = None
global_features = ['G1', 'G2', 'G3', 'studytime', 'failures', 'absences']
global_kmeans_model = None
global_cluster_summary = None # Store cluster summary for API calls
global_cluster_names = {} # To store GPT-generated cluster names

# Global variable for theme management
current_theme = "dark" # Initial theme

# Corrected primary_hue values for themes
themes_map = {
    "dark": gr.themes.Monochrome(primary_hue="violet"), # Changed "dark" to "violet" for a dark theme with violet accents
    "light": gr.themes.Soft(primary_hue=gr.themes.colors.purple) # Using Soft theme for a clean light mode with purple accents
}
plotly_templates_map = {
    "dark": 'plotly_dark',
    "light": 'plotly_white'
}

def get_gpt_interpretation(cluster_data, cluster_id, all_features_means=None):
    """Fetches a detailed interpretation and name for a cluster from GPT-4o."""
    if client is None:
        return {"name": f"Cluster {cluster_id} (AI Unavailable)", "description": "AI service not initialized."}

    prompt_parts = [
        f"Analyze the following average student performance metrics for a cluster (Cluster {cluster_id}):",
        f"Grades (G1, G2, G3 average): {((cluster_data['G1'] + cluster_data['G2'] + cluster_data['G3']) / 3):.2f}",
        f"Study Time (1=<2h, 4=>10h): {cluster_data['studytime']:.2f}",
        f"Failures: {cluster_data['failures']:.2f}",
        f"Absences: {cluster_data['absences']:.2f}",
        "\nBased on these metrics, provide a concise, descriptive name for this student cluster (e.g., 'High Achievers', 'Struggling Learners', 'Consistent Performers').",
        "Then, provide a detailed, easy-to-understand interpretation of this cluster's characteristics, explaining what defines these students and what their potential strengths or challenges might be.",
        "Your response MUST be a JSON object with two keys: 'name' (string) and 'description' (string).",
        "Strictly provide ONLY the JSON object. Do not include any conversational text or markdown formatting outside the JSON structure."
    ]

    if all_features_means is not None:
        prompt_parts.insert(1, "\nFor context, the overall average for these features across all students are:")
        prompt_parts.insert(2, f"Overall Avg Grades: {((all_features_means['G1'] + all_features_means['G2'] + all_features_means['G3']) / 3):.2f}")
        prompt_parts.insert(3, f"Overall Avg Study Time: {all_features_means['studytime']:.2f}")
        prompt_parts.insert(4, f"Overall Avg Failures: {all_features_means['failures']:.2f}")
        prompt_parts.insert(5, f"Overall Avg Absences: {all_features_means['absences']:.2f}")

    try:
        chat_completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an AI assistant specialized in interpreting student academic data and providing actionable insights. Be concise and professional."},
                {"role": "user", "content": "\n".join(prompt_parts)}
            ],
            response_format={"type": "json_object"}
        )
        response_content = chat_completion.choices[0].message.content
        interpretation = json.loads(response_content)
        return interpretation
    except Exception as e:
        print(f"Error fetching GPT-4o interpretation for Cluster {cluster_id}: {e}")
        return {"name": f"Cluster {cluster_id} (AI Error)", "description": "Could not generate interpretation due to an AI service error."}


def generate_overall_summary_gpt(df_description, cluster_summary):
    """Generates an overall summary of the student population and clusters using GPT-4o."""
    if client is None:
        return "AI service not initialized for summary generation."

    prompt = f"""
    Based on the following overall student statistics and identified clusters, provide a concise executive summary of the student population's performance and the key insights from the clustering analysis.

    Overall Student Statistics (df.describe()):
    {df_description.to_string()}

    Cluster Characteristics (Mean Values):
    {cluster_summary.to_string()}

    Focus on identifying the main types of students, their defining characteristics, and potential implications for educators.
    """
    try:
        chat_completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an AI assistant providing executive summaries of student academic data. Be professional, concise, and highlight key actionable insights."},
                {"role": "user", "content": prompt}
            ]
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        print(f"Error generating overall summary with GPT-4o: {e}")
        return "Could not generate overall summary due to an AI service error."


def get_personalized_recommendations_gpt(student_data, cluster_data, cluster_name):
    """Generates personalized recommendations for a student using GPT-4o."""
    if client is None:
        return "AI service not initialized for personalized recommendations."

    prompt = f"""
    Based on the following student's profile and the characteristics of their assigned cluster ('{cluster_name}'), provide personalized recommendations or areas for improvement.

    Student's Data:
    G1: {student_data['G1']}
    G2: {student_data['G2']}
    G3: {student_data['G3']}
    Study Time (1=<2h, 4=>10h): {student_data['studytime']}
    Failures: {student_data['failures']}
    Absences: {student_data['absences']}

    Their Cluster's Average Characteristics:
    Grades (G1, G2, G3 average): {((cluster_data['G1'] + cluster_data['G2'] + cluster_data['G3']) / 3):.2f}
    Study Time: {cluster_data['studytime']:.2f}
    Failures: {cluster_data['failures']:.2f}
    Absences: {cluster_data['absences']:.2f}

    Provide actionable advice focusing on academic strategies, time management, or seeking support, tailored to this student's specific situation within their cluster.
    """
    try:
        chat_completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an AI academic advisor providing empathetic and actionable personalized recommendations to students."},
                {"role": "user", "content": prompt}
            ]
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        print(f"Error generating personalized recommendations with GPT-4o: {e}")
        return "Could not generate personalized recommendations due to an AI service error."

def get_cluster_recommendations_gpt(cluster_data, cluster_name):
    """Generates general recommendations for an entire cluster using GPT-4o."""
    if client is None:
        return "AI service not initialized for cluster recommendations."

    prompt = f"""
    Based on the following average characteristics of the '{cluster_name}' cluster, provide general recommendations or strategies that could benefit students within this group.

    Cluster Average Characteristics:
    Grades (G1, G2, G3 average): {((cluster_data['G1'] + cluster_data['G2'] + cluster_data['G3']) / 3):.2f}
    Study Time (1=<2h, 4=>10h): {cluster_data['studytime']:.2f}
    Failures: {cluster_data['failures']:.2f}
    Absences: {cluster_data['absences']:.2f}

    Focus on broad strategies relevant to the cluster's overall profile (e.g., for 'High Achievers', suggest advanced learning opportunities; for 'Struggling Learners', suggest foundational support).
    """
    try:
        chat_completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an AI educational strategist providing general recommendations for student groups."},
                {"role": "user", "content": prompt}
            ]
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        print(f"Error generating cluster recommendations with GPT-4o: {e}")
        return "Could not generate cluster recommendations due to an AI service error."


def load_and_preprocess_data(file_obj):
    """
    Loads the student data from a Gradio File object, performs initial checks,
    selects features, and scales the data.
    Returns the original DataFrame, scaled DataFrame, and initial text outputs.
    """
    global global_df, global_scaled_df, global_kmeans_model, global_cluster_summary, global_cluster_names

    # Reset global states at the beginning of a new load operation
    global_df = None
    global_scaled_df = None
    global_kmeans_model = None
    global_cluster_summary = None
    global_cluster_names = {}

    if file_obj is None:
        gr.Info("Please upload a CSV file to begin.")
        # Return initial states for all outputs, including disabled buttons and cleared states
        return None, None, "No file uploaded.", \
               gr.update(interactive=False), gr.update(interactive=False), \
               gr.update(value=[], choices=[]), None, None, \
               gr.update(interactive=False), gr.update(interactive=False) # Disable run_clustering and overall_summary

    # file_obj is now directly the file path string because type="filepath"
    file_path = file_obj

    try:
        df = pd.read_csv(file_path)
    except Exception as e:
        gr.Error(f"Error loading CSV: {e}. Please ensure it's a valid CSV file.")
        # Return error message and keep buttons disabled, clear states
        return None, None, f"Error loading CSV: {e}", \
               gr.update(interactive=False), gr.update(interactive=False), \
               gr.update(value=[], choices=[]), None, None, \
               gr.update(interactive=False), gr.update(interactive=False) # Disable run_clustering and overall_summary

    output_text = f"Dataset has {df.shape[0]} rows and {df.shape[1]} columns.\n"

    # Check for missing values
    missing_values = df.isnull().sum()
    output_text += "\nMissing values before handling:\n"
    output_text += missing_values.to_string() + "\n"

    # Handle missing values: dropping rows with any missing values for simplicity.
    initial_rows = df.shape[0]
    df.dropna(inplace=True)
    if df.shape[0] < initial_rows:
        output_text += f"\nRemoved {initial_rows - df.shape[0]} rows due to missing values.\n"
    else:
        output_text += "\nNo missing values found.\n"

    output_text += "\nBasic statistics of the dataset:\n"
    output_text += df.describe().to_string() + "\n"

    # Select features for clustering
    missing_features = [f for f in global_features if f not in df.columns]
    if missing_features:
        gr.Error(f"Error: Missing required features in CSV: {', '.join(missing_features)}. Please check your dataset.")
        # Return error message and keep buttons disabled, clear states
        return None, None, f"Error: Missing required features: {', '.join(missing_features)}", \
               gr.update(interactive=False), gr.update(interactive=False), \
               gr.update(value=[], choices=[]), None, None, \
               gr.update(interactive=False), gr.update(interactive=False) # Disable run_clustering and overall_summary

    student_features = df[global_features]
    output_text += "\nSelected features for clustering (first 5 rows):\n"
    output_text += student_features.head().to_string() + "\n"

    # Normalizing data
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(student_features)
    scaled_df = pd.DataFrame(scaled_features, columns=global_features)
    output_text += "\nScaled features (first 5 rows):\n"
    output_text += scaled_df.head().to_string() + "\n"

    global_df = df
    global_scaled_df = scaled_df

    gr.Info("Data loaded and preprocessed successfully! You can now generate optimal K plots.")

    return gr.DataFrame(value=df.head()), gr.DataFrame(value=scaled_df.head()), output_text, \
               gr.update(interactive=True), gr.update(interactive=True), \
               gr.update(value=[], choices=[]), None, scaled_df, gr.update(interactive=True), gr.update(interactive=True) # Enable run_clustering and overall_summary buttons


def plot_optimal_clusters(scaled_df_from_state):
    """
    Determines the optimal number of clusters using
    the Elbow Method and Silhouette Score, returning Plotly figures.
    """
    if scaled_df_from_state is None:
        gr.Warning("Please load data first to plot optimal clusters.")
        return None, None, "Please load data first to plot optimal clusters.", gr.update(interactive=False)

    gr.Info("Generating Elbow and Silhouette plots... This may take a moment.")
    inertia = []
    silhouette_scores = []
    K = range(1, 11)
    K_silhouette = range(2, 11)

    for k in K:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(scaled_df_from_state)
        inertia.append(kmeans.inertia_)
        if k >= 2:
            score = silhouette_score(scaled_df_from_state, kmeans.labels_)
            silhouette_scores.append(score)

    # Use current_theme for plotly template
    current_plotly_template = plotly_templates_map[current_theme]

    elbow_fig = go.Figure(data=go.Scatter(x=list(K), y=inertia, mode='lines+markers'))
    elbow_fig.update_layout(
        title='Elbow Method to Find Optimal Number of Clusters',
        xaxis_title='Number of clusters (k)',
        yaxis_title='Inertia (Within-Cluster-Sum-of-Squares)',
        template=current_plotly_template
    )

    silhouette_fig = go.Figure(data=go.Scatter(x=list(K_silhouette), y=silhouette_scores, mode='lines+markers'))
    silhouette_fig.update_layout(
        title='Silhouette Score for Optimal Number of Clusters',
        xaxis_title='Number of clusters (k)',
        yaxis_title='Silhouette Score',
        template=current_plotly_template
    )
    gr.Info("Optimal K plots generated. Now you can select the number of clusters and run the analysis.")
    return elbow_fig, silhouette_fig, "Visual inspection of these plots helps determine the optimal 'k'. Look for the 'elbow' point in the Inertia plot and the highest point in the Silhouette Score plot.", gr.update(interactive=True) # Enable run_clustering_button


def perform_clustering_and_analysis(n_clusters):
    """
    Splits the code into two parts to enable better tracking.

    Applies K-Means clustering, adds cluster labels,
    analyzes cluster characteristics, and generates visualizations.
    """
    global global_df, global_scaled_df, global_kmeans_model, global_cluster_summary, global_cluster_names

    # Initialize a list of Nones for scatter plots (matching global_features length)
    initial_scatter_plots_output = [None] * len(global_features)

    if global_df is None or global_scaled_df is None:
        gr.Warning("Please load data first to perform clustering.")
        return None, None, None, None, "Please load data first to perform clustering.", gr.update(visible=False), \
               gr.update(value=[], choices=[]), "", "", *initial_scatter_plots_output, None, None, None, gr.update(interactive=False) # Added None for new plots and disable overall summary button

    if n_clusters < 2:
        gr.Warning("Number of clusters must be at least 2 for meaningful clustering.")
        return None, None, None, None, "Number of clusters must be at least 2.", gr.update(visible=False), \
               gr.update(value=[], choices=[]), "", "", *initial_scatter_plots_output, None, None, None, gr.update(interactive=False) # Added None for new plots and disable overall summary button

    gr.Info(f"Performing KMeans with {n_clusters} clusters and generating interpretations... This may take a moment due to AI calls.")
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(global_scaled_df)
    global_df['Cluster'] = clusters
    global_kmeans_model = kmeans

    cluster_summary = global_df.groupby('Cluster')[global_features].mean()
    global_cluster_summary = cluster_summary # Store for other functions

    # Calculate overall means for context in GPT-4o interpretation
    all_features_means = global_df[global_features].mean()

    interpretation_text = "<div class='interpretation-container'>"
    cluster_options = []
    global_cluster_names = {} # Reset global cluster names
    for i in range(len(cluster_summary)):
        # Get GPT-4o interpretation for each cluster
        gpt_interpretation = get_gpt_interpretation(cluster_summary.loc[i], i, all_features_means)
        cluster_name = gpt_interpretation.get('name', f'Cluster {i}')
        global_cluster_names[str(i)] = cluster_name # Store name for dropdown

        interpretation_text += f"<div class='cluster-card'>"
        interpretation_text += f"<h4 class='cluster-title'>‚ú® {cluster_name} (Cluster {i})</h4>" # Display both name and ID
        interpretation_text += f"<p>{gpt_interpretation.get('description', 'No detailed description available.')}</p>"
        interpretation_text += f"<ul>"
        cluster_data = cluster_summary.loc[i]
        grade_avg = (cluster_data['G1'] + cluster_data['G2'] + cluster_data['G3']) / 3
        interpretation_text += f"<li>Average Grades (G1, G2, G3): <strong>{grade_avg:.2f}</strong> (G1: {cluster_data['G1']:.2f}, G2: {cluster_data['G2']:.2f}, G3: {cluster_data['G3']:.2f})</li>"
        interpretation_text += f"<li>Average Study Time: <strong>{cluster_data['studytime']:.2f}</strong> (1: <2h, 2: 2-5h, 3: 5-10h, 4: >10h)</li>"
        interpretation_text += f"<li>Average Failures: <strong>{cluster_data['failures']:.2f}</strong></li>"
        interpretation_text += f"<li>Average Absences: <strong>{cluster_data['absences']:.2f}</strong></li>"
        interpretation_text += f"</ul></div>"
        cluster_options.append(f"Cluster {i}: {cluster_name}") # Format for dropdown: "Cluster ID: Name"
    interpretation_text += "</div>"

    # Use current_theme for plotly template
    current_plotly_template = plotly_templates_map[current_theme]

    cluster_counts = global_df['Cluster'].value_counts().reset_index()
    cluster_counts.columns = ['Cluster', 'Count']
    bar_fig = px.bar(cluster_counts, x='Cluster', y='Count',
                     title='Number of Students in Each Cluster',
                     color='Cluster', template=current_plotly_template)

    pair_fig = px.scatter_matrix(global_df, dimensions=global_features, color='Cluster', # Removed color_continuous_scale
                                 title='Pair Plot of Features by Cluster',
                                 height=800, width=800, opacity=0.7)
    pair_fig.update_traces(diagonal_visible=False)
    pair_fig.update_layout(template=current_plotly_template)

    # --- New Visualizations ---
    # Scatter plots for feature distributions by cluster
    scatter_plot_figs = []
    for feature in global_features:
        fig = px.scatter(global_df, x='Cluster', y=feature, color='Cluster',
                         title=f'Distribution of {feature} by Cluster (Scatter)',
                         template=current_plotly_template,
                         hover_data=global_features) # Show all features on hover
        scatter_plot_figs.append(fig)

    # For Radar Chart:
    # Prepare data for radar chart - normalize cluster means
    cluster_means_normalized = cluster_summary.copy()
    for feature in global_features:
        min_val = global_df[feature].min()
        max_val = global_df[feature].max()
        if max_val - min_val > 0: # Avoid division by zero
            cluster_means_normalized[feature] = (cluster_means_normalized[feature] - min_val) / (max_val - min_val)
        else:
            cluster_means_normalized[feature] = 0.5 # If all values are same, put at middle

    radar_data = []
    for i, row in cluster_means_normalized.iterrows():
        r_values = row[global_features].tolist()
        # Close the loop for radar chart
        r_values.append(r_values[0])

        theta_values = global_features + [global_features[0]] # Close the loop for theta

        radar_data.append(
            go.Scatterpolar(
                r=r_values,
                theta=theta_values,
                fill='toself',
                name=global_cluster_names.get(str(i), f'Cluster {i}')
            )
        )

    radar_fig = go.Figure(data=radar_data)
    radar_fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 1]
            )),
        showlegend=True,
        title='Cluster Profiles (Normalized Feature Means)',
        template=current_plotly_template
    )

    # PCA Scatter Plot
    from sklearn.decomposition import PCA
    pca = PCA(n_components=2)
    principal_components = pca.fit_transform(global_scaled_df)
    pca_df = pd.DataFrame(data = principal_components, columns = ['principal component 1', 'principal component 2'])
    pca_df['Cluster'] = global_df['Cluster'] # Add cluster labels
    pca_fig = px.scatter(pca_df, x='principal component 1', y='principal component 2', color='Cluster',
                         title='PCA of Student Data by Cluster', template=current_plotly_template)
    pca_fig.update_layout(template=current_plotly_template)

    # Heatmap of Cluster Means
    # Ensure cluster_summary is properly indexed by Cluster ID
    heatmap_data = cluster_summary.transpose() # Features as rows, Clusters as columns
    heatmap_fig = px.imshow(heatmap_data,
                             labels=dict(x="Cluster", y="Feature", color="Mean Value"),
                             x=[global_cluster_names.get(str(i), f'Cluster {i}') for i in heatmap_data.columns],
                             y=heatmap_data.index,
                             color_continuous_scale='Viridis',
                             title='Heatmap of Cluster Mean Feature Values',
                             template=current_plotly_template)
    heatmap_fig.update_layout(template=current_plotly_template)
    # --- End New Visualizations ---


    output_filename = "student_data_clustered.csv"
    global_df.to_csv(output_filename, index=False)

    gr.Info("Clustering analysis complete! Explore the results below.")

    return (
        gr.DataFrame(value=global_df[['G1', 'G2', 'G3', 'studytime', 'failures', 'absences', 'Cluster']].head()),
        gr.DataFrame(value=cluster_summary),
        bar_fig,
        pair_fig,
        interpretation_text,
        gr.File(value=output_filename, visible=True, label="Download Clustered Data"),
        gr.update(choices=cluster_options, value=cluster_options[0] if cluster_options else None),
        "Select a student from the table above to get personalized recommendations.", # Clear personalized recommendations output
        "", # Clear cluster recommendations output
        *[fig for fig in scatter_plot_figs], # Unpack list of scatter plot figures
        radar_fig, # Radar chart figure
        pca_fig, # PCA plot
        heatmap_fig, # Heatmap
        gr.update(interactive=True) # Enable overall summary button
    )

def show_cluster_data(selected_cluster_label):
    """Filters and displays data for a selected cluster and clears recommendations."""
    if global_df is None:
        gr.Warning("Please load data and run clustering first.")
        # Clear both recs and disable button
        return None, "Please load data and run clustering first.", "", gr.update(interactive=False)

    if selected_cluster_label is None or selected_cluster_label == "":
        # Show head if nothing selected, clear both recs and disable button
        return gr.DataFrame(value=global_df.head()), "Select a student from the table above to get personalized recommendations.", "", gr.update(interactive=False)

    try:
        # Extract cluster ID from label (e.g., "Cluster 0: High Achievers" -> "0")
        cluster_id_str = selected_cluster_label.split(':')[0].replace('Cluster ', '').strip()
        selected_cluster_id = int(cluster_id_str)

        filtered_df = global_df[global_df['Cluster'] == selected_cluster_id]
        gr.Info(f"Displaying students for {selected_cluster_label}.")
        # Clear both recommendations and disable button when new cluster is selected
        return gr.DataFrame(value=filtered_df), "Select a student from the table above to get personalized recommendations.", "", gr.update(interactive=False)
    except (ValueError, IndexError) as e:
        gr.Error(f"Error selecting cluster: {e}. Please ensure a valid cluster is selected.")
        return None, "Error: Invalid cluster selection.", "", gr.update(interactive=False)


def get_recommendations_for_selected_student(evt: gr.SelectData):
    """
    Generates personalized recommendations for a student selected from the DataFrame.
    This function is directly triggered by gr.DataFrame.select, receiving gr.SelectData.
    """
    global global_df, global_cluster_summary, global_cluster_names

    if global_df is None or global_cluster_summary is None:
        gr.Warning("Please load data and run clustering first to get recommendations.")
        # Return default message and disable button
        return "Please load data and run clustering first.", gr.update(interactive=False)

    if evt.index is None:
        # Return default message and disable button if no row is selected
        return "Please select a row from the table to get recommendations.", gr.update(interactive=False)

    gr.Info("Generating personalized recommendations... This may take a moment.")
    try:
        # Get the full student data row from the global_df using the selected index
        student_idx = evt.index[0] # For row selection, index[0] is the row index
        student_data = global_df.iloc[student_idx]

        cluster_id = student_data['Cluster']
        cluster_data = global_cluster_summary.loc[cluster_id]

        # Get cluster name from stored global_cluster_names
        cluster_name = global_cluster_names.get(str(cluster_id), f'Cluster {cluster_id}')

        recommendations = get_personalized_recommendations_gpt(student_data, cluster_data, cluster_name)
        # Return recommendations and enable the button for future selections
        return recommendations, gr.update(interactive=True)

    except Exception as e:
        print(f"Error generating recommendations: {e}")
        # Return error message and disable the button
        return f"Could not generate recommendations due to an error: {e}", gr.update(interactive=False)


def get_recommendations_for_selected_cluster(selected_cluster_label):
    """
    Generates general recommendations for a selected cluster.
    """
    global global_df, global_cluster_summary, global_cluster_names

    if global_df is None or global_cluster_summary is None:
        gr.Warning("Please load data and run clustering first to get cluster recommendations.")
        return "Please load data and run clustering first."

    if selected_cluster_label is None or selected_cluster_label == "":
        return "Please select a cluster from the dropdown to get recommendations."

    gr.Info(f"Generating general recommendations for {selected_cluster_label}... This may take a moment.")
    try:
        # Extract cluster ID from label (e.g., "Cluster 0: High Achievers" -> "0")
        cluster_id_str = selected_cluster_label.split(':')[0].replace('Cluster ', '').strip()
        selected_cluster_id = int(cluster_id_str)

        cluster_data = global_cluster_summary.loc[selected_cluster_id]
        cluster_name = global_cluster_names.get(str(selected_cluster_id), f'Cluster {selected_cluster_id}')

        recommendations = get_cluster_recommendations_gpt(cluster_data, cluster_name)
        return recommendations
    except (ValueError, IndexError) as e:
        gr.Error(f"Error getting cluster recommendations: {e}. Please ensure a valid cluster is selected.")
        return f"Could not generate recommendations due to an error: {e}"


def generate_overall_summary():
    """Generates and displays an overall summary report."""
    global global_df, global_cluster_summary

    if global_df is None or global_cluster_summary is None:
        gr.Warning("Please load data and run clustering first to generate a summary.")
        return "Please load data and run clustering first."

    gr.Info("Generating overall summary report... This may take a moment.")
    summary_text = generate_overall_summary_gpt(global_df.describe(), global_cluster_summary)
    return summary_text

def clear_personalized_recommendations():
    """Clears the personalized recommendations output."""
    gr.Info("Personalized recommendations cleared.")
    return "Select a student from the table above to get personalized recommendations."

def clear_cluster_recommendations():
    """Clears the cluster-level recommendations output."""
    gr.Info("Cluster recommendations cleared.")
    return "Select a cluster and click 'Get Cluster Recommendations' to see general advice for the group."


def reset_dashboard():
    """Resets all Gradio components and global variables."""
    global global_df, global_scaled_df, global_kmeans_model, global_cluster_summary, global_cluster_names
    global_df = None
    global_scaled_df = None
    global_kmeans_model = None
    global_cluster_summary = None
    global_cluster_names = {}

    gr.Info("Dashboard reset. Please upload a new CSV to start over.")
    # Initialize a list of Nones for scatter plots (matching global_features length)
    initial_scatter_plots_output = [None] * len(global_features)

    return (
        None, # raw_data_head
        None, # scaled_data_head
        "Dashboard has been reset. Upload a new CSV to begin.", # preprocessing_output
        gr.update(interactive=False), # plot_optimal_k_button
        gr.update(interactive=False), # run_clustering_button
        None, # elbow_plot
        None, # silhouette_plot
        "Click 'Generate Optimal K Plots' after loading data to see the analysis.", # optimal_k_text
        None, # clustered_data_head
        None, # cluster_summary_df
        None, # cluster_distribution_plot
        None, # pair_plot_visualization
        "Cluster interpretations will appear here after clustering.", # cluster_interpretation_markdown
        gr.File(value=None, visible=False), # download_file_output
        gr.update(value=[], choices=[]), # cluster_select_dropdown
        None, # cluster_data_view
        None, # scaled_df_state_component
        "Overall summary will appear here.", # overall_summary_output
        "Select a student from the table above to get personalized recommendations.", # personalized_recommendations_output
        "", # cluster_recommendations_output
        gr.update(interactive=False), # overall_summary_button
        gr.update(interactive=False), # get_personalized_recommendations_button
        *initial_scatter_plots_output, # Reset scatter plots
        None, # Reset radar chart
        None, # Reset PCA plot
        None # Reset Heatmap
    )

def toggle_theme(
    current_plotly_elbow_fig, current_plotly_silhouette_fig,
    current_plotly_bar_fig, current_plotly_pair_fig,
    *current_plotly_scatter_figs, # Capture all scatter plots
    current_plotly_radar_fig, current_plotly_pca_fig, current_plotly_heatmap_fig
):
    """Toggles between dark and light themes and updates Plotly figures."""
    global current_theme

    # Determine the new theme
    new_theme_name = "light" if current_theme == "dark" else "dark"
    new_theme = themes_map[new_theme_name]
    new_plotly_template = plotly_templates_map[new_theme_name]
    current_theme = new_theme_name # Update global theme state

    # Update Plotly figures' templates if they exist
    if current_plotly_elbow_fig:
        current_plotly_elbow_fig.update_layout(template=new_plotly_template)
    if current_plotly_silhouette_fig:
        current_plotly_silhouette_fig.update_layout(template=new_plotly_template)
    if current_plotly_bar_fig:
        current_plotly_bar_fig.update_layout(template=new_plotly_template)
    if current_plotly_pair_fig:
        current_plotly_pair_fig.update_layout(template=new_plotly_template)
    
    updated_scatter_figs = []
    for fig in current_plotly_scatter_figs:
        if fig:
            fig.update_layout(template=new_plotly_template)
        updated_scatter_figs.append(fig)

    if current_plotly_radar_fig:
        current_plotly_radar_fig.update_layout(template=new_plotly_template)
    if current_plotly_pca_fig:
        current_plotly_pca_fig.update_layout(template=new_plotly_template)
    if current_plotly_heatmap_fig:
        current_plotly_heatmap_fig.update_layout(template=new_plotly_template)

    gr.Info(f"Switched to {new_theme_name.capitalize()} Mode.")

    # Return the new theme and updated figures
    return (
        new_theme,
        current_plotly_elbow_fig, current_plotly_silhouette_fig,
        current_plotly_bar_fig, current_plotly_pair_fig,
        *updated_scatter_figs, # Unpack updated scatter plots
        current_plotly_radar_fig, current_plotly_pca_fig, current_plotly_heatmap_fig
    )

# Gradio Interface
# Initial output values for scatter_plot_outputs for the Gradio interface definition
initial_scatter_plot_outputs = [gr.Plot(label=f"Distribution of {feature} by Cluster") for feature in global_features]

custom_css = """
/* Base styles - these will be overridden by Gradio's themes for common elements
   or can be used for custom components not fully themed by Gradio. */
body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}

h1 {
    text-align: center;
    font-size: 2.8em;
    font-weight: bold;
    padding: 20px 0;
    margin-bottom: 30px;
    border-bottom: 3px solid rgba(75,0,130,0.4);
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
}

/* Theme-specific H1 background (handled by Gradio theme, but for custom elements) */
/* These will be primarily overridden by Gradio's built-in themes but kept for custom cases */
body.dark h1 {
    color: #fff;
    background: linear-gradient(90deg, #4B0082, #8A2BE2); /* Indigo to BlueViolet gradient */
}

body.light h1 {
    color: #4B0082;
    background: linear-gradient(90deg, #DDA0DD, #E6E6FA); /* Plum to Lavender gradient */
}


/* General heading styling - will mostly be overridden by Gradio themes */
h2 {
    border-bottom: 2px solid;
    padding-bottom: 10px;
    margin-top: 30px;
    font-size: 1.8em;
}

h3 {
    font-size: 1.4em;
    margin-top: 20px;
    margin-bottom: 10px;
}

h4.cluster-title {
    padding: 10px 15px;
    border-radius: 5px;
    margin-top: 0;
    margin-bottom: 10px;
    font-size: 1.3em;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

/* Theme-specific cluster-title background */
body.dark h4.cluster-title {
    background: linear-gradient(45deg, #8A2BE2, #9932CC); /* BlueViolet to DarkOrchid gradient */
    color: white;
}

body.light h4.cluster-title {
    background: linear-gradient(45deg, #FFDEAD, #F0E68C); /* NavajoWhite to Khaki gradient */
    color: #4B0082;
}

.interpretation-container {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 20px;
    padding: 20px 0;
}

.cluster-card {
    border: 1px solid;
    border-radius: 8px;
    padding: 20px;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.08);
    transition: transform 0.2s ease-in-out;
}

body.dark .cluster-card {
    background-color: #2a2a2a; /* Dark background for cards */
    border-color: #444;
    color: #eee;
}

body.light .cluster-card {
    background-color: #ffffff; /* Light background for cards */
    border-color: #e0e0e0;
    color: #444;
}


.cluster-card:hover {
    transform: translateY(-5px);
}

.cluster-card p {
    line-height: 1.6;
    margin-bottom: 15px;
}

.cluster-card ul {
    list-style: none;
    padding: 0;
    margin: 0;
}

.cluster-card ul li {
    margin-bottom: 8px;
    padding: 8px 12px;
    border-radius: 4px;
    border-left: 3px solid; /* Plum accent */
    font-size: 0.95em;
}

body.dark .cluster-card ul li {
    background-color: #3a3a3a;
    border-left-color: #9370DB; /* MediumPurple accent */
    color: #ddd;
}

body.light .cluster-card ul li {
    background-color: #f9f9f9;
    border-left-color: #DDA0DD; /* Plum accent */
    color: #333;
}


.gradio-container {
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.1);
    border-radius: 10px;
    overflow: hidden;
}

/* Customizing buttons - ensure !important for overrides */
button.primary {
    background: linear-gradient(45deg, #6A5ACD, #8A2BE2) !important; /* SlateBlue to BlueViolet */
    border: none !important;
    color: white !important;
    font-weight: bold !important;
    padding: 10px 20px !important;
    border-radius: 5px !important;
    transition: all 0.3s ease !important;
}

button.primary:hover {
    box-shadow: 0 5px 15px rgba(106, 90, 205, 0.4) !important;
    transform: translateY(-2px) !important;
}

button.secondary {
    background-color: #E6E6FA !important; /* Lavender */
    border: 1px solid #9370DB !important; /* MediumPurple */
    color: #4B0082 !important; /* Indigo */
    font-weight: bold !important;
    padding: 8px 15px !important;
    border-radius: 5px !important;
    transition: all 0.3s ease !important;
}

body.dark button.secondary {
    background-color: #555 !important;
    border-color: #888 !important;
    color: #eee !important;
}

body.dark button.secondary:hover {
    background-color: #666 !important;
    border-color: #aaa !important;
}


button.secondary:hover {
    background-color: #D8BFD8 !important; /* Thistle */
    border-color: #8A2BE2 !important;
    transform: translateY(-1px) !important;
}

/* Specific styling for gradio info/warnings */
.gradio-info {
    background-color: #e0f7fa !important; /* Light cyan */
    border-left: 5px solid #00BCD4 !important; /* Cyan */
    color: #006064 !important; /* Dark Cyan */
}

.gradio-warning {
    background-color: #fff8e1 !important; /* Light orange */
    border-left: 5px solid #FFC107 !important; /* Amber */
    color: #E65100 !important; /* Orange Dark */
}

.gradio-error {
    background-color: #ffebee !important; /* Light red */
    border-left: 5px solid #F44336 !important; /* Red */
    color: #C62828 !important; /* Dark Red */
}

/* Custom box styling for gr.Group */
.my-box {
    border: 1px solid;
    border-radius: 8px;
    padding: 20px;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.08);
    margin-bottom: 20px; /* Add some spacing between boxes */
}

body.dark .my-box {
    background-color: #2a2a2a;
    border-color: #444;
}

body.light .my-box {
    background-color: #ffffff;
    border-color: #e0e0e0;
}

/* Ensure text in Markdown components adapts */
.gradio-markdown {
    color: var(--body-text-color) !important; /* This will dynamically pick up theme color */
}
"""

with gr.Blocks(theme=themes_map[current_theme], css=custom_css) as demo:
    # State component to pass scaled_df between functions without re-uploading
    scaled_df_state_component = gr.State(value=None)

    # Place the theme toggle button prominently
    with gr.Row():
        gr.Markdown("<h1 style='text-align: center; flex-grow: 1;'>üéì Student Performance Clustering Dashboard</h1>")
        theme_button = gr.Button("Toggle Theme", variant="secondary", size="sm", min_width=150)
    
    gr.Markdown("""
    <p style="text-align: center; color: var(--body-text-color); font-size: 1.1em;">Uncover hidden patterns in student data to identify distinct performance groups using K-Means and AI-driven insights.</p>
    """)

    with gr.Tabs():
        with gr.TabItem("üöÄ Data Overview"):
            gr.Markdown("## Upload Data & Preprocessing")
            # Changed type="file" to type="filepath"
            file_input = gr.File(label="Upload Student Performance CSV", type="filepath", file_types=[".csv"])
            with gr.Column():
                raw_data_head = gr.DataFrame(label="Raw Data Preview (First 5 Rows)")
                scaled_data_head = gr.DataFrame(label="Scaled Data Preview (First 5 Rows)")
                preprocessing_output = gr.Textbox(label="Preprocessing Log", lines=10)

            with gr.Row():
                reset_button = gr.Button("Reset Dashboard", variant="secondary")

        with gr.TabItem("üìä Optimal Clusters (K)"):
            gr.Markdown("## Determine Optimal Number of Clusters")
            gr.Markdown("### Use Elbow Method and Silhouette Score to find the best 'k'.")

            with gr.Row():
                plot_optimal_k_button = gr.Button("Generate Optimal K Plots", interactive=False, variant="primary")

            with gr.Row():
                elbow_plot = gr.Plot(label="Elbow Method Plot", scale=1)
                silhouette_plot = gr.Plot(label="Silhouette Score Plot", scale=1)

            optimal_k_text = gr.Markdown(value="Click 'Generate Optimal K Plots' after loading data to see the analysis.")

            gr.Markdown("---")
            gr.Markdown("### Run Clustering with Chosen K")
            with gr.Row():
                n_clusters_input = gr.Slider(minimum=2, maximum=10, value=3, step=1, label="Select Number of Clusters (k)")
                run_clustering_button = gr.Button("Run Clustering & Analyze", variant="primary", interactive=False)

        with gr.TabItem("üìà Clustering Results & Insights"):
            gr.Markdown("## Clustering Results & Visualizations")

            with gr.Row():
                clustered_data_head = gr.DataFrame(label="Clustered Data Preview (First 5 Rows)")
                cluster_summary_df = gr.DataFrame(label="Cluster Mean Characteristics")

            gr.Markdown("---")
            gr.Markdown("### Cluster Distribution")
            cluster_distribution_plot = gr.Plot(label="Number of Students in Each Cluster")
            download_file_output = gr.File(label="Download Clustered Data", visible=False)

            gr.Markdown("---")
            gr.Markdown("### AI-Generated Cluster Interpretations")
            cluster_interpretation_markdown = gr.HTML(value="Cluster interpretations will appear here after clustering.")

            gr.Markdown("---")
            gr.Markdown("### Feature Relationships by Cluster")
            pair_plot_visualization = gr.Plot(label="Pair Plot of Features by Cluster")

            gr.Markdown("---")
            gr.Markdown("### Detailed Cluster Profiles")
            # Reuse the list of Plot components defined earlier
            with gr.Accordion("Individual Feature Distributions", open=False):
                # Dynamically add Plot components to the interface
                for plot_comp in initial_scatter_plot_outputs:
                    plot_comp.render()

            with gr.Row():
                radar_plot_figure = gr.Plot(label="Cluster Profiles (Radar Chart)")
                pca_plot_figure = gr.Plot(label="PCA of Student Data by Cluster")

            heatmap_figure = gr.Plot(label="Heatmap of Cluster Mean Feature Values")


        with gr.TabItem("üí° Recommendations"):
            gr.Markdown("## Personalized & Cluster-Level Recommendations")

            with gr.Column():
                # FIX: Replaced gr.Box with gr.Group and added elem_classes for styling
                with gr.Group(elem_classes="my-box"):
                    gr.Markdown("### Recommendations for a Selected Student")
                    student_data_view = gr.DataFrame(label="Students in Selected Cluster (Click a row to get recommendations)", interactive=True)
                    personalized_recommendations_output = gr.Markdown("Select a student from the table above to get personalized recommendations.")
                    clear_personalized_recs_button = gr.Button("Clear Personalized Recommendations", variant="secondary")

                # FIX: Replaced gr.Box with gr.Group and added elem_classes for styling
                with gr.Group(elem_classes="my-box"):
                    gr.Markdown("### General Recommendations for a Cluster")
                    cluster_select_dropdown = gr.Dropdown([], label="Select a Cluster")
                    get_cluster_recommendations_button = gr.Button("Get Cluster Recommendations", variant="primary")
                    cluster_recommendations_output = gr.Markdown("Select a cluster and click 'Get Cluster Recommendations' to see general advice for the group.")
                    clear_cluster_recs_button = gr.Button("Clear Cluster Recommendations", variant="secondary")

        with gr.TabItem("üìù Executive Summary"):
            gr.Markdown("## Overall Executive Summary")
            gr.Markdown("Get a high-level overview of the student population and key insights from the clustering analysis.")
            overall_summary_button = gr.Button("Generate Overall Summary", variant="primary", interactive=False)
            overall_summary_output = gr.Markdown("Overall summary will appear here.")


    # --- Event Listeners (using direct component references) ---

    # 1. Data Loading and Preprocessing
    file_input.upload(
        load_and_preprocess_data,
        inputs=[file_input],
        outputs=[raw_data_head, scaled_data_head, preprocessing_output,
                 plot_optimal_k_button, run_clustering_button, # Enable buttons
                 cluster_select_dropdown, student_data_view, # Clear dropdown and student view
                 scaled_df_state_component, # Update state
                 get_cluster_recommendations_button, overall_summary_button # Enable other buttons
                 ]
    )

    # 2. Optimal K Plotting
    plot_optimal_k_button.click(
        plot_optimal_clusters,
        inputs=[scaled_df_state_component],
        outputs=[elbow_plot, silhouette_plot, optimal_k_text, run_clustering_button] # Enable run_clustering_button here
    )

    # 3. Clustering and Analysis
    run_clustering_button.click(
        perform_clustering_and_analysis,
        inputs=[n_clusters_input],
        outputs=[clustered_data_head, cluster_summary_df, cluster_distribution_plot,
                 pair_plot_visualization, cluster_interpretation_markdown,
                 download_file_output, cluster_select_dropdown,
                 personalized_recommendations_output, cluster_recommendations_output,
                 *initial_scatter_plot_outputs, radar_plot_figure, pca_plot_figure, heatmap_figure, # Unpack outputs for new plots
                 overall_summary_button # Enable overall summary button
                 ]
    )

    # 4. Cluster Data View and Personalized Recommendations
    cluster_select_dropdown.change(
        show_cluster_data,
        inputs=[cluster_select_dropdown],
        outputs=[student_data_view, personalized_recommendations_output, cluster_recommendations_output, get_cluster_recommendations_button] # Disable cluster rec button
    )

    student_data_view.select(
        get_recommendations_for_selected_student,
        inputs=None, # The data is implicitly passed by gr.SelectData
        outputs=[personalized_recommendations_output, get_cluster_recommendations_button] # Enable cluster rec button here (as it's triggered by selecting a student from *any* cluster)
    )

    clear_personalized_recs_button.click(
        clear_personalized_recommendations,
        inputs=[],
        outputs=[personalized_recommendations_output]
    )

    # 5. Cluster-Level Recommendations
    get_cluster_recommendations_button.click(
        get_recommendations_for_selected_cluster,
        inputs=[cluster_select_dropdown],
        outputs=[cluster_recommendations_output]
    )

    clear_cluster_recs_button.click(
        clear_cluster_recommendations,
        inputs=[],
        outputs=[cluster_recommendations_output]
    )

    # 6. Overall Summary
    overall_summary_button.click(
        generate_overall_summary,
        inputs=[],
        outputs=[overall_summary_output]
    )

    # 7. Reset Dashboard
    reset_button.click(
        reset_dashboard,
        inputs=[],
        outputs=[
            raw_data_head, scaled_data_head, preprocessing_output,
            plot_optimal_k_button, run_clustering_button,
            elbow_plot, silhouette_plot, optimal_k_text,
            clustered_data_head, cluster_summary_df,
            cluster_distribution_plot, pair_plot_visualization,
            cluster_interpretation_markdown, download_file_output,
            cluster_select_dropdown, student_data_view,
            scaled_df_state_component, overall_summary_output,
            personalized_recommendations_output, cluster_recommendations_output,
            overall_summary_button, get_cluster_recommendations_button,
            *initial_scatter_plot_outputs, radar_plot_figure, pca_plot_figure, heatmap_figure
        ]
    )

    # 8. Theme Toggle
    theme_button.click(
        toggle_theme,
        inputs=[
            elbow_plot, silhouette_plot,
            cluster_distribution_plot, pair_plot_visualization,
            *initial_scatter_plot_outputs, radar_plot_figure, pca_plot_figure, heatmap_figure
        ],
        outputs=[
            demo, # This special output changes the theme of the entire Blocks
            elbow_plot, silhouette_plot,
            cluster_distribution_plot, pair_plot_visualization,
            *initial_scatter_plot_outputs, radar_plot_figure, pca_plot_figure, heatmap_figure
        ]
    )

demo.launch(share=True)